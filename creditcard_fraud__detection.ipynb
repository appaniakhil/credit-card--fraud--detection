{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "creditcard_fraud _detection",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "P2thyecf0hn7",
        "outputId": "3dd9a5a3-b473-4d8e-fff5-b0def010e90d"
      },
      "source": [
        "#Packages related to general operating system & warnings\n",
        "import os \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#Packages related to data importing, manipulation, exploratory data #analysis, data understanding\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import Series, DataFrame\n",
        "from termcolor import colored as cl # text customization\n",
        "#Packages related to data visualizaiton\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "#Setting plot sizes and type of plot\n",
        "plt.rc(\"font\", size=14)\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.gray()\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.impute import MissingIndicator, SimpleImputer\n",
        "from sklearn.preprocessing import  PolynomialFeatures, KBinsDiscretizer, FunctionTransformer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer, OrdinalEncoder\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.tsa as tsa\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet, Lasso, Ridge\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz\n",
        "from sklearn.ensemble import BaggingClassifier, BaggingRegressor,RandomForestClassifier,RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor, AdaBoostClassifier, AdaBoostRegressor \n",
        "from sklearn.svm import LinearSVC, LinearSVR, SVC, SVR\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import export_text\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6zOzm2H9bI9"
      },
      "source": [
        "Importing Dataset\n",
        "Importing the dataset using the kaggle api. and after downloading it and extracting it we can use pandas module in python to import it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfdKsVsAHmuP"
      },
      "source": [
        "! mkdir ~/.kaggle "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nph_k0xvJnGX"
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5e8RsUU0mZZ",
        "outputId": "ca1a4ef1-d8c4-4a0f-9e8d-a607a1ca5f12"
      },
      "source": [
        "! kaggle datasets download mlg-ulb/creditcardfraud"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading creditcardfraud.zip to /content\n",
            " 97% 64.0M/66.0M [00:00<00:00, 79.1MB/s]\n",
            "100% 66.0M/66.0M [00:00<00:00, 84.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d2UIEHF7-g_",
        "outputId": "f1087e5c-db1d-493e-d91f-97a035707103"
      },
      "source": [
        "! unzip creditcardfraud.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  creditcardfraud.zip\n",
            "  inflating: creditcard.csv          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsYBnd3ea-A5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sKaCr3r8og_"
      },
      "source": [
        "df=pd.read_csv('/content/creditcard.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "agHISsbg83dz",
        "outputId": "ced0c578-b437-407c-cee8-ff4654cd892f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFbFNQzP93-j",
        "outputId": "09c11c54-339a-4475-fa78-ff7ebe3b6d97"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdMhYkJHDuSp"
      },
      "source": [
        "As per the count per column, we have no null values. Also, feature selection is not the case for this use case. Anyway, you can try applying feature selection mechanisms to check if the results are optimised.\n",
        "I have observed in our data 28 features are transformed versions of PCA but the Amount is the original one. And, while checking the minimum and maximum is in the amount — I found the difference is huge that can deviate our result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2RlNrCoDtk7"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "V4oOJRKX85wX",
        "outputId": "b4a7342b-2f79-4fd4-dd33-320b5a50daf4"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>3.919560e-15</td>\n",
              "      <td>5.688174e-16</td>\n",
              "      <td>-8.769071e-15</td>\n",
              "      <td>2.782312e-15</td>\n",
              "      <td>-1.552563e-15</td>\n",
              "      <td>2.010663e-15</td>\n",
              "      <td>-1.694249e-15</td>\n",
              "      <td>-1.927028e-16</td>\n",
              "      <td>-3.137024e-15</td>\n",
              "      <td>1.768627e-15</td>\n",
              "      <td>9.170318e-16</td>\n",
              "      <td>-1.810658e-15</td>\n",
              "      <td>1.693438e-15</td>\n",
              "      <td>1.479045e-15</td>\n",
              "      <td>3.482336e-15</td>\n",
              "      <td>1.392007e-15</td>\n",
              "      <td>-7.528491e-16</td>\n",
              "      <td>4.328772e-16</td>\n",
              "      <td>9.049732e-16</td>\n",
              "      <td>5.085503e-16</td>\n",
              "      <td>1.537294e-16</td>\n",
              "      <td>7.959909e-16</td>\n",
              "      <td>5.367590e-16</td>\n",
              "      <td>4.458112e-15</td>\n",
              "      <td>1.453003e-15</td>\n",
              "      <td>1.699104e-15</td>\n",
              "      <td>-3.660161e-16</td>\n",
              "      <td>-1.206049e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>1.088850e+00</td>\n",
              "      <td>1.020713e+00</td>\n",
              "      <td>9.992014e-01</td>\n",
              "      <td>9.952742e-01</td>\n",
              "      <td>9.585956e-01</td>\n",
              "      <td>9.153160e-01</td>\n",
              "      <td>8.762529e-01</td>\n",
              "      <td>8.493371e-01</td>\n",
              "      <td>8.381762e-01</td>\n",
              "      <td>8.140405e-01</td>\n",
              "      <td>7.709250e-01</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>-2.458826e+01</td>\n",
              "      <td>-4.797473e+00</td>\n",
              "      <td>-1.868371e+01</td>\n",
              "      <td>-5.791881e+00</td>\n",
              "      <td>-1.921433e+01</td>\n",
              "      <td>-4.498945e+00</td>\n",
              "      <td>-1.412985e+01</td>\n",
              "      <td>-2.516280e+01</td>\n",
              "      <td>-9.498746e+00</td>\n",
              "      <td>-7.213527e+00</td>\n",
              "      <td>-5.449772e+01</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>-5.354257e-01</td>\n",
              "      <td>-7.624942e-01</td>\n",
              "      <td>-4.055715e-01</td>\n",
              "      <td>-6.485393e-01</td>\n",
              "      <td>-4.255740e-01</td>\n",
              "      <td>-5.828843e-01</td>\n",
              "      <td>-4.680368e-01</td>\n",
              "      <td>-4.837483e-01</td>\n",
              "      <td>-4.988498e-01</td>\n",
              "      <td>-4.562989e-01</td>\n",
              "      <td>-2.117214e-01</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>-9.291738e-02</td>\n",
              "      <td>-3.275735e-02</td>\n",
              "      <td>1.400326e-01</td>\n",
              "      <td>-1.356806e-02</td>\n",
              "      <td>5.060132e-02</td>\n",
              "      <td>4.807155e-02</td>\n",
              "      <td>6.641332e-02</td>\n",
              "      <td>-6.567575e-02</td>\n",
              "      <td>-3.636312e-03</td>\n",
              "      <td>3.734823e-03</td>\n",
              "      <td>-6.248109e-02</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>4.539234e-01</td>\n",
              "      <td>7.395934e-01</td>\n",
              "      <td>6.182380e-01</td>\n",
              "      <td>6.625050e-01</td>\n",
              "      <td>4.931498e-01</td>\n",
              "      <td>6.488208e-01</td>\n",
              "      <td>5.232963e-01</td>\n",
              "      <td>3.996750e-01</td>\n",
              "      <td>5.008067e-01</td>\n",
              "      <td>4.589494e-01</td>\n",
              "      <td>1.330408e-01</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>2.374514e+01</td>\n",
              "      <td>1.201891e+01</td>\n",
              "      <td>7.848392e+00</td>\n",
              "      <td>7.126883e+00</td>\n",
              "      <td>1.052677e+01</td>\n",
              "      <td>8.877742e+00</td>\n",
              "      <td>1.731511e+01</td>\n",
              "      <td>9.253526e+00</td>\n",
              "      <td>5.041069e+00</td>\n",
              "      <td>5.591971e+00</td>\n",
              "      <td>3.942090e+01</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time            V1  ...         Amount          Class\n",
              "count  284807.000000  2.848070e+05  ...  284807.000000  284807.000000\n",
              "mean    94813.859575  3.919560e-15  ...      88.349619       0.001727\n",
              "std     47488.145955  1.958696e+00  ...     250.120109       0.041527\n",
              "min         0.000000 -5.640751e+01  ...       0.000000       0.000000\n",
              "25%     54201.500000 -9.203734e-01  ...       5.600000       0.000000\n",
              "50%     84692.000000  1.810880e-02  ...      22.000000       0.000000\n",
              "75%    139320.500000  1.315642e+00  ...      77.165000       0.000000\n",
              "max    172792.000000  2.454930e+00  ...   25691.160000       1.000000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJAk32WfAT9J"
      },
      "source": [
        "Data Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm3PgrPQ89q7",
        "outputId": "0155e660-b9eb-433b-e496-8057417a7bf0"
      },
      "source": [
        "Total_transactions = len(df)\n",
        "normal = len(df[df.Class == 0])\n",
        "fraudulent = len(df[df.Class == 1])\n",
        "fraud_percentage = round(fraudulent/normal*100, 2)\n",
        "print(cl('Total number of Trnsactions are {}'.format(Total_transactions)))\n",
        "print(cl('Number of Normal Transactions are {}'.format(normal)))\n",
        "print(cl('Number of fraudulent Transactions are {}'.format(fraudulent)))\n",
        "print(cl('Percentage of fraud Transactions is {}'.format(fraud_percentage)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of Trnsactions are 284807\u001b[0m\n",
            "Number of Normal Transactions are 284315\u001b[0m\n",
            "Number of fraudulent Transactions are 492\u001b[0m\n",
            "Percentage of fraud Transactions is 0.17\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t-fTFmHAA1u",
        "outputId": "f723842b-788e-4ca6-9af1-65e431efa009"
      },
      "source": [
        "print('min amount:',min(df.Amount))\n",
        "print('max amount:',max(df.Amount))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min amount: 0.0\n",
            "max amount: 25691.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "tMhPkH-YHi22",
        "outputId": "e327f0c9-5846-4973-8396-fbebae2cec59"
      },
      "source": [
        "sns.kdeplot(x='Amount', data=df)\n",
        "plt.title('Amount distribution')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "TXmkeS-t0zTh",
        "outputId": "0591a5c4-ceaa-4411-ccd7-d1a79a9fd663"
      },
      "source": [
        "# using seaborns countplot to show distribution of questions in dataset\n",
        "fig, ax = plt.subplots()\n",
        "g = sns.countplot(df.Class, palette='viridis')\n",
        "g.set_xticklabels(['Not Fraud', 'Fraud'])\n",
        "g.set_yticklabels([])\n",
        "\n",
        "# function to show values on bars\n",
        "def show_values_on_bars(axs):\n",
        "    def _show_on_single_plot(ax):        \n",
        "        for p in ax.patches:\n",
        "            _x = p.get_x() + p.get_width() / 2\n",
        "            _y = p.get_y() + p.get_height()\n",
        "            value = '{:.0f}'.format(p.get_height())\n",
        "            ax.text(_x, _y, value, ha=\"center\") \n",
        "\n",
        "    if isinstance(axs, np.ndarray):\n",
        "        for idx, ax in np.ndenumerate(axs):\n",
        "            _show_on_single_plot(ax)\n",
        "    else:\n",
        "        _show_on_single_plot(axs)\n",
        "show_values_on_bars(ax)\n",
        "\n",
        "sns.despine(left=True, bottom=True)\n",
        "plt.xlabel('')\n",
        "plt.ylabel('')\n",
        "plt.title('Distribution of Transactions', fontsize=30)\n",
        "plt.tick_params(axis='x', which='major', labelsize=15)\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cjhD_YEG00p"
      },
      "source": [
        "df.drop(['Time'], axis=1, inplace=True)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V6WsRTJG_Lx",
        "outputId": "f92eed35-bf48-46ee-c5db-6f72e0d25a34"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkroU9LcHCk4"
      },
      "source": [
        "df.drop_duplicates(inplace=True)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUgW1aUTHJg3",
        "outputId": "2991618e-dbca-4de6-fe86-89a7df9b6788"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(275663, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yVZt_BqHLU8"
      },
      "source": [
        "y = df.Class\n",
        "X = df.drop('Class', axis=1)\n",
        "\n",
        "# setting up testing and training sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6oYAUlqLRKY"
      },
      "source": [
        "Model Building\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DikZQt3_HUXu"
      },
      "source": [
        "#decision tree\n",
        "dtclf = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
        "dtclf.fit(X_train, y_train)\n",
        "dtclf_predict = dtclf.predict(X_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKibp_og3Nl3",
        "outputId": "a9733f3e-96b6-43d6-b9fe-79bf680219bc"
      },
      "source": [
        "print('Unique predicted labels: ', (np.unique(dtclf_predict)))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique predicted labels:  [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIgbZJjQLV83",
        "outputId": "1e372045-fae9-4d60-ebef-b095e7a379b2"
      },
      "source": [
        "print('Accuracy score of the Decision Tree model is {}'.format(accuracy_score(y_test,dtclf_predict )))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of the Decision Tree model is 0.9993615415868594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2k7K86XLjTG",
        "outputId": "cc11b991-edea-4b22-875b-20677a88816a"
      },
      "source": [
        "print('F1 score of the Decision Tree model is {}'.format(f1_score(y_test,dtclf_predict)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score of the Decision Tree model is 0.7962962962962963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elupJykaembU",
        "outputId": "dba83243-456b-4f62-e441-f6631e10e72d"
      },
      "source": [
        "confusion_matrix(y_test, dtclf_predict, labels = [0, 1])\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[68786,    15],\n",
              "       [   29,    86]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MussvkSxeofX"
      },
      "source": [
        "n = 7\n",
        "KNN = KNeighborsClassifier(n_neighbors = n)\n",
        "KNN.fit(X_train, y_train)\n",
        "knn_predict = KNN.predict(X_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5Q0r4Z23Ufz",
        "outputId": "7ec1fd73-4a2a-409c-a5c3-ce2fe8c9ddf8"
      },
      "source": [
        "print('Unique predicted labels: ', (np.unique(knn_predict)))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique predicted labels:  [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS3QIGVOezuY",
        "outputId": "0e0b8c84-e853-4cff-fb5a-1e62f69e6858"
      },
      "source": [
        "print('Accuracy score of the K-Nearest Neighbors model is {}'.format(accuracy_score(y_test,knn_predict)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of the K-Nearest Neighbors model is 0.999318010331418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWkR9LiMe7wi",
        "outputId": "fee3faf9-39ad-43da-c630-b5af64f8fbbd"
      },
      "source": [
        "print('F1 score of the K-Nearest Neighbors model is {}'.format(f1_score(y_test, knn_predict)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score of the K-Nearest Neighbors model is 0.7614213197969543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzGLqwsRgM9L"
      },
      "source": [
        "#logistic regression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "lr_predict= lr.predict(X_test)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRJc-p353Yug",
        "outputId": "e7749586-1f2a-4e0d-f896-59f54758d77c"
      },
      "source": [
        "print('Unique predicted labels: ', (np.unique(lr_predict)))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique predicted labels:  [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIrZkB-RgSD2",
        "outputId": "72834687-3566-4cac-9979-482656fad633"
      },
      "source": [
        "print('Accuracy score of the Logistic Regression model is {}'.format(accuracy_score(y_test,lr_predict)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of the Logistic Regression model is 0.99907133321725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmnnUHPlgSAY",
        "outputId": "2ac5a664-673a-46c4-937c-73965dbc5dfe"
      },
      "source": [
        "print('F1 score of the Logistic Regression model is {}'.format(f1_score(y_test,lr_predict)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score of the Logistic Regression model is 0.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2qs2bxa0kIjg",
        "outputId": "0d285abc-fdbc-4b57-dc90-c2b4c2c2f748"
      },
      "source": [
        "df = pd.DataFrame({'Real Values':y_test, 'Predicted Values':lr_predict})\n",
        "df"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Real Values</th>\n",
              "      <th>Predicted Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33142</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239748</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281082</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186668</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101248</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220199</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214956</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3346</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19308</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149626</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68916 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Real Values  Predicted Values\n",
              "33142             0                 0\n",
              "239748            0                 0\n",
              "281082            0                 0\n",
              "186668            0                 0\n",
              "101248            0                 0\n",
              "...             ...               ...\n",
              "220199            0                 0\n",
              "214956            0                 0\n",
              "3346              0                 0\n",
              "19308             0                 0\n",
              "149626            0                 0\n",
              "\n",
              "[68916 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbGPI6LngR9W"
      },
      "source": [
        "#svm\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "svm_predict = svm.predict(X_test)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk_wNhbYgR5N",
        "outputId": "b0975e24-5306-4993-b488-2459ea39146d"
      },
      "source": [
        "print('Accuracy score of the Support Vector Machines model is {}'.format(accuracy_score(y_test, svm_predict)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of the Support Vector Machines model is 0.9987666144291601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvqsa_vOL4zO",
        "outputId": "1d95ff71-9131-42f2-e35c-1df3bb61351f"
      },
      "source": [
        "print('F1 score of the Support Vector Machines model is {}'.format(f1_score(y_test, svm_predict)))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score of the Support Vector Machines model is 0.49101796407185627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLr-uhuPZZBP"
      },
      "source": [
        "rf = RandomForestClassifier(max_depth = 4)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_predict = rf.predict(X_test)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOD66D41ZjkB",
        "outputId": "0aa41608-e646-4f52-ec7e-2897a923e492"
      },
      "source": [
        "print('Accuracy score of the Random Forest model is {}'.format(accuracy_score(y_test, rf_predict)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of the Random Forest model is 0.9993905624238203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoPJ6CDQZl2n",
        "outputId": "58cc9260-ff1b-418d-9b99-337e5a26393b"
      },
      "source": [
        "print('F1 score of the Random Forest model is {}'.format(f1_score(y_test, rf_predict)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score of the Random Forest model is 0.792079207920792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6fCOvWnZn35"
      },
      "source": [
        "xgb = XGBClassifier(max_depth = 4)\n",
        "xgb.fit(X_train, y_train)\n",
        "xgb_predict = xgb.predict(X_test)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36pzbgAzZn0g",
        "outputId": "fe550c9a-b2e2-45cc-ab9e-10df88ee3880"
      },
      "source": [
        "print('Accuracy score of the XGBoost model is {}'.format(accuracy_score(y_test, xgb_predict)))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of the XGBoost model is 0.9995501770271055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0BeWblYZnxN",
        "outputId": "5edff4d5-9600-456e-dd75-fa77a3eaf51f"
      },
      "source": [
        "print('F1 score of the XGBoost model is {}'.format(f1_score(y_test, xgb_predict)))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score of the XGBoost model is 0.8502415458937198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ZtWKGF3wP9"
      },
      "source": [
        "Always split into test and train sets BEFORE trying any resampling techniques! Oversampling before splitting the data can allow the exact same observations to be present in both the test and train sets! This can allow our model to simply memorize specific data points and cause overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFUwqz-v39oq"
      },
      "source": [
        "df=pd.read_csv('/content/creditcard.csv')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFlRUuM1Zntv",
        "outputId": "dc8cb02d-6520-43f2-e248-b6a9d98233a8"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "\n",
        "# Separate input features and target\n",
        "y = df.Class\n",
        "X = df.drop('Class', axis=1)\n",
        "\n",
        "# setting up testing and training sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
        "\n",
        "# concatenate our training data back together\n",
        "X = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "# separate minority and majority classes\n",
        "not_fraud = X[X.Class==0]\n",
        "fraud = X[X.Class==1]\n",
        "\n",
        "# upsample minority\n",
        "fraud_upsampled = resample(fraud,\n",
        "                          replace=True, # sample with replacement\n",
        "                          n_samples=len(not_fraud), # match number in majority class\n",
        "                          random_state=27) # reproducible results\n",
        "\n",
        "# combine majority and upsampled minority\n",
        "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
        "\n",
        "# check new class counts\n",
        "upsampled.Class.value_counts()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    213245\n",
              "0    213245\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKMHK4aXa-Cl"
      },
      "source": [
        "# trying logistic regression again with the balanced dataset\n",
        "y_train = upsampled.Class\n",
        "X_train = upsampled.drop('Class', axis=1)\n",
        "\n",
        "upsampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
        "\n",
        "upsampled_pred = upsampled.predict(X_test)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_Kbajks4La1",
        "outputId": "35861a73-0e9c-4236-de88-991d5a7557ae"
      },
      "source": [
        "#ACCURACY SCORE\n",
        "accuracy_score(y_test, upsampled_pred)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9807589674447347"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jakF1FJ4PaD",
        "outputId": "fbd18526-3223-4acd-faab-3f00c6aa8059"
      },
      "source": [
        "#F1 SCORE\n",
        "f1_score(y_test, upsampled_pred)\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14375000000000002"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Mvig8Me24Qpj",
        "outputId": "534971a7-d910-4214-c8b5-87a23c89b36d"
      },
      "source": [
        "# confusion matrix\n",
        "pd.DataFrame(confusion_matrix(y_test, upsampled_pred))\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69717</td>\n",
              "      <td>1353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17</td>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0     1\n",
              "0  69717  1353\n",
              "1     17   115"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJRkp0634ZIX",
        "outputId": "cea2230c-934c-4ec4-8179-326d502d1851"
      },
      "source": [
        "#RECALL SCORE\n",
        "from sklearn.metrics import recall_score\n",
        "recall_score(y_test, upsampled_pred)\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8712121212121212"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxRXkr3D60P3"
      },
      "source": [
        "Our accuracy score decreased after upsampling, but the model is now predicting both classes more equally, making it an improvement over our plain logistic regression above.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwANlZK57hFM"
      },
      "source": [
        "#svm\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "svm_predict = svm.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqqOZJ9w7hBX"
      },
      "source": [
        "print('Accuracy score of the Support Vector Machines model is {}'.format(accuracy_score(y_test, svm_predict)))\n",
        "print('F1 score of the Support Vector Machines model is {}'.format(f1_score(y_test, svm_predict)))\n",
        "print('confusion matric:',confusion_matrix(y_test, dtclf_predict, labels = [0, 1]))\n",
        "print('recall score:',recall_score(y_test, upsampled_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctewn8s-B3Zj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxnT3w7DB3O3"
      },
      "source": [
        "Undersampling Majority Class:\n",
        "Undersampling can be defined as removing some observations of the majority class. Undersampling can be a good choice when you have a ton of data -think millions of rows. But a drawback to undersampling is that we are removing information that may be valuable.\n",
        "\n",
        "We will again use the resampling module from Scikit-Learn to randomly remove samples from the majority class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cqsh-o47g6_",
        "outputId": "3b044ce9-39a8-4420-cb2e-deff56fc035a"
      },
      "source": [
        "# still using our separated classes fraud and not_fraud from above\n",
        "\n",
        "# downsample majority\n",
        "not_fraud_downsampled = resample(not_fraud,\n",
        "                                replace = False, # sample without replacement\n",
        "                                n_samples = len(fraud), # match minority n\n",
        "                                random_state = 27) # reproducible results\n",
        "\n",
        "# combine minority and downsampled majority\n",
        "downsampled = pd.concat([not_fraud_downsampled, fraud])\n",
        "\n",
        "# checking counts\n",
        "downsampled.Class.value_counts()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    360\n",
              "0    360\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzQjXg0EB0Dq"
      },
      "source": [
        "# trying logistic regression again with the undersampled dataset\n",
        "\n",
        "y_train = downsampled.Class\n",
        "X_train = downsampled.drop('Class', axis=1)\n",
        "\n",
        "undersampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
        "\n",
        "undersampled_pred = undersampled.predict(X_test)\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu0UZpBEBy55",
        "outputId": "511a6344-99b8-491a-911b-9e5e579b4f37"
      },
      "source": [
        "print('Accuracy score of the logistic regression model is {}'.format(accuracy_score(y_test, undersampled_pred)))\n",
        "print('F1 score of the Logistic regression model is {}'.format(f1_score(y_test,undersampled_pred)))\n",
        "print('confusion matric:',confusion_matrix(y_test, undersampled_pred, labels = [0, 1]))\n",
        "print('recall score:',recall_score(y_test, undersampled_pred))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of the logistic regression model is 0.9758574197354007\n",
            "F1 score of the Logistic regression model is 0.11710323574730355\n",
            "confusion matric: [[69369  1701]\n",
            " [   18   114]]\n",
            "recall score: 0.8636363636363636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fasVEyZ4VinE"
      },
      "source": [
        "Generate Synthetic Samples\n",
        "SMOTE or Synthetic Minority Oversampling Technique is a popular algorithm to creates sythetic observations of the minority class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQHUk9RDBt3z"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Separate input features and target\n",
        "y = df.Class\n",
        "X = df.drop('Class', axis=1)\n",
        "\n",
        "# setting up testing and training sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
        "\n",
        "sm = SMOTE(random_state=27, sampling_strategy=1.0)\n",
        "X_train, y_train = sm.fit_resample(X_train, y_train)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hoZm_cw7g4Y",
        "outputId": "546c9e87-1ae4-41ad-dc93-926ddc52e192"
      },
      "source": [
        "smote = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
        "\n",
        "smote_pred = smote.predict(X_test)\n",
        "\n",
        "# Checking accuracy\n",
        "accuracy_score(y_test, smote_pred)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9858571388444145"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On3OvbZt7g1C",
        "outputId": "92b95545-3e60-485c-c1c1-9f2702b64f28"
      },
      "source": [
        "print('Accuracy score of the logistic regression model is {}'.format(accuracy_score(y_test, undersampled_pred)))\n",
        "print('F1 score of the Logistic regression model is {}'.format(f1_score(y_test,undersampled_pred)))\n",
        "print('confusion matric:',confusion_matrix(y_test, undersampled_pred, labels = [0, 1]))\n",
        "print('recall score:',recall_score(y_test, undersampled_pred))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of the logistic regression model is 0.9758574197354007\n",
            "F1 score of the Logistic regression model is 0.11710323574730355\n",
            "confusion matric: [[69369  1701]\n",
            " [   18   114]]\n",
            "recall score: 0.8636363636363636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSrZ4QVlhBXk"
      },
      "source": [
        "These are just some of the many possible methods to try when dealing with imbalanced datasets, and not an exhaustive list. Some others methods to consider are collecting more data or choosing different resampling ratios - you don't have to have exactly a 1:1 ratio! You should always try several approaches and then decide which is best for your problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PICXKzXv7gwQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6X5FzUo7gst"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-U6dp4hiN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3u1b7Ga6t0Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}